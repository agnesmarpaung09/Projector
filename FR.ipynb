{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e4598399",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 2 # Number of samples to record (of each person)\n",
    "everyFrame = 24 # record an observation once every everyFrame frames\n",
    "shapePath = ('C:\\Windows\\System32\\cmd.exe')\n",
    "camSrc = 0 # This should set the webcam to be the input, but you may need to change the value on your system\n",
    "personNames = [['Patricia'],['Cia']] # Names of the people being recognized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "cf5ff96e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [57], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimutils\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mdlib\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcv2\u001b[39;00m \u001b[38;5;66;03m# This one is the OpenCV library.\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m ; plt\u001b[38;5;241m.\u001b[39mrcdefaults\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "from imutils.video import VideoStream\n",
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import imutils\n",
    "import time\n",
    "import dlib\n",
    "import cv2 # This one is the OpenCV library.\n",
    "import matplotlib.pyplot as plt ; plt.rcdefaults\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0498868c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getArea(x,y,z):\n",
    "    a = x-y\n",
    "    b = z-y\n",
    "    area = np.abs( a[0] * b[1] - a[1] * b[0] ) / 2\n",
    "    return area\n",
    "\n",
    "def getAngle(x,y,z):\n",
    "    a = x-y\n",
    "    b = z-y\n",
    "    cosineAngle = np.dot(a,b) / ( np.linalg.norm(a) * np.linalg.norm(b) )\n",
    "    angle = np.arccos(cosineAngle)\n",
    "    return angle\n",
    "    \n",
    "def getLength(x,y):\n",
    "    length = np.linalg.norm(x-y)\n",
    "    return length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8c8497f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def facedat(scaledShape):\n",
    "    dat = [\n",
    "        ### Lengths    \n",
    "        # Outer eyes width:\n",
    "        getLength(scaledShape[45,],scaledShape[36,]),\n",
    "        # Inner eyes width:\n",
    "        getLength(scaledShape[42,],scaledShape[39,]),\n",
    "        # Nose length:\n",
    "        getLength(scaledShape[27,],scaledShape[33,]),\n",
    "        # Nose width:\n",
    "        getLength(scaledShape[35,],scaledShape[31,]),\n",
    "        # Outer mouth width:\n",
    "        getLength(scaledShape[54,],scaledShape[48,]),\n",
    "        # Inner mouth width:\n",
    "        getLength(scaledShape[64,],scaledShape[60,]),\n",
    "        # Outer mouth height:\n",
    "        getLength(scaledShape[51,],scaledShape[57,]),\n",
    "        # Inner mouth height:\n",
    "        getLength(scaledShape[62,],scaledShape[66,]),\n",
    "        # Jaw to eye, left and right:\n",
    "        getLength(scaledShape[36,],scaledShape[10,]) +\n",
    "        getLength(scaledShape[16,],scaledShape[45,]),\n",
    "        # Lower jaw width:\n",
    "        getLength(scaledShape[12,],scaledShape[4,]),\n",
    "        # Eye to mouth, left and right:\n",
    "        getLength(scaledShape[39,],scaledShape[48,]) +\n",
    "        getLength(scaledShape[42,],scaledShape[54,]),\n",
    "        # Eyebrow widths, left and right:\n",
    "        getLength(scaledShape[21,],scaledShape[17,]) + \n",
    "        getLength(scaledShape[22,],scaledShape[26,]),\n",
    "        # Nose to mouth:\n",
    "        getLength(scaledShape[33,],scaledShape[51,]),\n",
    "        # Outer eye to eyebrow, left and right:\n",
    "        getLength(scaledShape[17,],scaledShape[36,]) +\n",
    "        getLength(scaledShape[26,],scaledShape[45,]),\n",
    "        # Inner eye to eyebrow, left and right:\n",
    "        getLength(scaledShape[21,],scaledShape[39,]) +\n",
    "        getLength(scaledShape[22,],scaledShape[42,]),\n",
    "        # Mouth to lower jaw, left and right:\n",
    "        getLength(scaledShape[4,],scaledShape[48,]) +\n",
    "        getLength(scaledShape[12,],scaledShape[54,]),\n",
    "        # Mouth to chin:\n",
    "        getLength(scaledShape[57,],scaledShape[8,]),\n",
    "        # Inner eyebrow width:\n",
    "        getLength(scaledShape[21,],scaledShape[22,]),\n",
    "        # Total jaw length\n",
    "        np.sum(np.linalg.norm(\n",
    "                np.diff(scaledShape[:17,],axis=0),axis=1)),\n",
    "        #\n",
    "        ### Areas\n",
    "        # Nose area:\n",
    "        getArea(scaledShape[27,],scaledShape[31,],scaledShape[33,]),\n",
    "        # Eye-nose area, left and right:\n",
    "        getArea(scaledShape[39,],scaledShape[27,],scaledShape[31,]) +\n",
    "        getArea(scaledShape[42,],scaledShape[27,],scaledShape[35,]),\n",
    "        # Eye-mouth area, left and right:\n",
    "        getArea(scaledShape[36,],scaledShape[39,],scaledShape[48,]) +\n",
    "        getArea(scaledShape[42,],scaledShape[45,],scaledShape[54,]),\n",
    "        # Nose-mouth area, left and right:\n",
    "        getArea(scaledShape[31,],scaledShape[33,],scaledShape[51,]) +\n",
    "        getArea(scaledShape[33,],scaledShape[51,],scaledShape[35,]),\n",
    "        # Eyebrow-outer eye area, left and right:\n",
    "        getArea(scaledShape[17,],scaledShape[21,],scaledShape[36,]) + \n",
    "        getArea(scaledShape[22,],scaledShape[26,],scaledShape[45,]),\n",
    "        # Eye-eyebrow-jaw area, left and right:\n",
    "        getArea(scaledShape[0,],scaledShape[17,],scaledShape[36,]) +\n",
    "        getArea(scaledShape[16,],scaledShape[26,],scaledShape[45,]),\n",
    "        # Eye-mouth-jaw area, left and right:\n",
    "        getArea(scaledShape[0,],scaledShape[36,],scaledShape[48,]) +\n",
    "        getArea(scaledShape[16,],scaledShape[45,],scaledShape[54,]),\n",
    "        # Mouth-lower jaw-chin area, left and right:\n",
    "        getArea(scaledShape[48,],scaledShape[4,],scaledShape[8,]) +\n",
    "        getArea(scaledShape[54,],scaledShape[12,],scaledShape[8,]),\n",
    "        # \n",
    "        ### Angles\n",
    "        # Eye-nose-mouth angles, left and right\n",
    "        getAngle(scaledShape[31,],scaledShape[39,],scaledShape[48,]) + \n",
    "        getAngle(scaledShape[35,],scaledShape[42,],scaledShape[54,]),\n",
    "        # Mouth-jaw-lower jaw angles, left and right\n",
    "        getAngle(scaledShape[48,],scaledShape[0,],scaledShape[4,]) + \n",
    "        getAngle(scaledShape[54,],scaledShape[16,],scaledShape[12,]),\n",
    "        # Nose-eye-eyebrow angles, left and right\n",
    "        getAngle(scaledShape[27,],scaledShape[39,],scaledShape[21,]) +\n",
    "        getAngle(scaledShape[27,],scaledShape[42,],scaledShape[22,])\n",
    "    ]\n",
    "    return(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "46ed3383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaleFace(shape):\n",
    "    chinPt = shape[8]\n",
    "    scaledShape = shape - chinPt\n",
    "    # Get and correct face angle\n",
    "    faceAngle = np.arctan(\n",
    "            (scaledShape[16,1]-scaledShape[0,1])/(\n",
    "                    scaledShape[16,0]-scaledShape[0,0]))\n",
    "    cosFA = np.cos(faceAngle)\n",
    "    sinFA = np.sin(faceAngle)\n",
    "    rotMat = [[cosFA, -sinFA],[sinFA, cosFA]]\n",
    "    scaledShape = np.matmul(scaledShape,rotMat)\n",
    "    faceWidth = scaledShape[16,0] - scaledShape[0,0]\n",
    "    faceHeight = scaledShape[8,1] - scaledShape[27,1]\n",
    "    scaledShape = scaledShape / [faceWidth, faceHeight]\n",
    "    return(scaledShape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "599fedef",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 30 # Number of covariates to record\n",
    "X = np.zeros([2*n,p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e69e3e71",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m detector \u001b[38;5;241m=\u001b[39m \u001b[43mdlib\u001b[49m\u001b[38;5;241m.\u001b[39mget_frontal_face_detector()\n\u001b[0;32m      2\u001b[0m predictor \u001b[38;5;241m=\u001b[39m dlib\u001b[38;5;241m.\u001b[39mshape_predictor(shapePath)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dlib' is not defined"
     ]
    }
   ],
   "source": [
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(shapePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "19e33548",
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = VideoStream(src=camSrc).start()\n",
    "time.sleep(1.0) # Just to make sure the camera has time to wake up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "345f5cea",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [49], line 14\u001b[0m\n\u001b[0;32m     11\u001b[0m     gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# detect faces in the grayscale frame\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     rects \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m(gray, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     16\u001b[0m rect \u001b[38;5;241m=\u001b[39m rects[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# loop over the face detections\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detector' is not defined"
     ]
    }
   ],
   "source": [
    "ii=0 # Counts how many times we've looped\n",
    "samps=0 # Counts how many samples have been gathered\n",
    "while True:\n",
    "    # grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "    # channels\n",
    "    rects = []\n",
    "    while np.size(rects) == 0:\n",
    "        frame = vs.read()\n",
    "        frame = imutils.resize(frame, width=450)\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        #\n",
    "        # detect faces in the grayscale frame\n",
    "        rects = detector(gray, 0)\n",
    "    \n",
    "    rect = rects[0]\n",
    "    \n",
    "    # loop over the face detections\n",
    "    if np.mod(ii,everyFrame)==0:\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    "        \n",
    "        ##############\n",
    "        # get centered version scaled wrt face width and height\n",
    "        scaledShape = scaleFace(shape)\n",
    "        \n",
    "        if n>0:\n",
    "            # Gather covariates\n",
    "            X[samps,] = facedat(scaledShape)\n",
    "        \n",
    "        samps += 1 # Increment sample counter\n",
    "        \n",
    "        ##################\n",
    "        \n",
    "    #########\n",
    "    # Draw on the face in a way that helps visualize the covariates being collected.\n",
    "    cv2.drawContours(frame, [\n",
    "            cv2.convexHull(shape[[27,33,31]]),\n",
    "            cv2.convexHull(shape[[27,33,35]]),\n",
    "            cv2.convexHull(shape[[51,33,31]]),\n",
    "            cv2.convexHull(shape[[51,33,35]]),\n",
    "            cv2.convexHull(shape[[27,39,31]]),\n",
    "            cv2.convexHull(shape[[27,35,42]]),\n",
    "            cv2.convexHull(shape[[22,45,42]]),\n",
    "            cv2.convexHull(shape[[36,39,21]]),\n",
    "            cv2.convexHull(shape[[21,27,22]]),\n",
    "            cv2.convexHull(shape[[36,39,48]]),\n",
    "            cv2.convexHull(shape[[42,45,54]]),\n",
    "            cv2.convexHull(shape[[48,54,8]]),\n",
    "            cv2.convexHull(shape[[4,48,8]]),\n",
    "            cv2.convexHull(shape[[8,54,12]]),\n",
    "            cv2.convexHull(shape[[4,48,0]]),\n",
    "            cv2.convexHull(shape[[54,12,16]]),\n",
    "            cv2.convexHull(shape[[0,36,17]]),\n",
    "            cv2.convexHull(shape[[45,26,16]]),\n",
    "            cv2.convexHull(shape[[17,21]]),\n",
    "            cv2.convexHull(shape[[22,26]]),\n",
    "            cv2.convexHull(shape[[57,8]]),\n",
    "            cv2.convexHull(shape[[51,57]]),\n",
    "            cv2.convexHull(shape[[62,66]]),\n",
    "            cv2.convexHull(shape[[60,64]])\n",
    "            ], -1, (0,255,0),1)\n",
    "\n",
    "    # show the frame along with how many samples have been recorded\n",
    "    cv2.putText(frame, \"SAMPLES: {}\".format(samps), (275, 30),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2)\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    #cv2.imwrite('images\\\\'+str(ii).zfill(5)+'.png',frame)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\") or samps == 2*n:\n",
    "        break  \n",
    "    \n",
    "    # if we've got n samples of the first person, prompt user to switch people\n",
    "    if samps == n:\n",
    "        input(\"Switch faces and press enter to continue...\")\n",
    "        ii = -1 # Start over\n",
    "    \n",
    "    # increment counter\n",
    "    ii+=1\n",
    "    \n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d2d32fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.zeros([2*n,1])\n",
    "Y[n:2*n] = 1\n",
    "Y = np.array(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7864cf21",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'RandomForestClassifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [51], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m clf \u001b[38;5;241m=\u001b[39m \u001b[43mRandomForestClassifier\u001b[49m(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,oob_score\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m clf\u001b[38;5;241m.\u001b[39mfit(X,Y\u001b[38;5;241m.\u001b[39mravel())\n",
      "\u001b[1;31mNameError\u001b[0m: name 'RandomForestClassifier' is not defined"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100,oob_score=True)\n",
    "# Train the model\n",
    "clf.fit(X,Y.ravel())\n",
    "# Don't need data any more\n",
    "del X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "72efde0d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclf\u001b[49m\u001b[38;5;241m.\u001b[39moob_score_)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'clf' is not defined"
     ]
    }
   ],
   "source": [
    "print(clf.oob_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a19e8f75",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [53], line 12\u001b[0m\n\u001b[0;32m      1\u001b[0m objects \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOuter eyes width\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInner eyes width\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNose length\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNose width\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      2\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOuter mouth width\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInner mouth width\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOuter mouth height\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      3\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInner mouth height\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJaw to eye\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLower jaw width\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMouth-low jaw-chin area\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEye-nose-mouth angle\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMouth-jaw-low jaw angle\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNose-eye-brow angle\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m ypos \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(objects))\n\u001b[1;32m---> 12\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m6\u001b[39m))\n\u001b[0;32m     13\u001b[0m idxs \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(clf\u001b[38;5;241m.\u001b[39mfeature_importances_) \u001b[38;5;66;03m# We sort to list the features in order of descending importance\u001b[39;00m\n\u001b[0;32m     14\u001b[0m plt\u001b[38;5;241m.\u001b[39mbarh(ypos,clf\u001b[38;5;241m.\u001b[39mfeature_importances_[idxs],align\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcenter\u001b[39m\u001b[38;5;124m'\u001b[39m,alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "objects = ('Outer eyes width','Inner eyes width','Nose length','Nose width',\n",
    "           'Outer mouth width','Inner mouth width','Outer mouth height',\n",
    "           'Inner mouth height','Jaw to eye','Lower jaw width',\n",
    "           'Eye to mouth','Eyebrow widths','Nose to mouth',\n",
    "           'Outer eye to brow','Inner eye to brow','Mouth to lower jaw',\n",
    "           'Mouth to chin','Inner brow width','Total jaw length',\n",
    "           'Nose area','Eye-nose area','Eye-mouth area','Nose-mouth area',\n",
    "           'Brow-outer eye area','Eye-brow-jaw area','Eye-mouth-jaw area',\n",
    "           'Mouth-low jaw-chin area','Eye-nose-mouth angle',\n",
    "           'Mouth-jaw-low jaw angle','Nose-eye-brow angle')\n",
    "ypos = np.arange(len(objects))\n",
    "plt.figure(figsize=(4,6))\n",
    "idxs = np.argsort(clf.feature_importances_) # We sort to list the features in order of descending importance\n",
    "plt.barh(ypos,clf.feature_importances_[idxs],align='center',alpha=0.5)\n",
    "plt.yticks(ypos,[objects[j] for j in idxs])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4000c076",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [54], line 16\u001b[0m\n\u001b[0;32m     13\u001b[0m gray \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(frame, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# detect faces in the grayscale frame\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m rects \u001b[38;5;241m=\u001b[39m \u001b[43mdetector\u001b[49m(gray, \u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# loop over the face detections\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m rect \u001b[38;5;129;01min\u001b[39;00m rects:\n\u001b[0;32m     20\u001b[0m     \u001b[38;5;66;03m# determine the facial landmarks for the face region, then\u001b[39;00m\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;66;03m# convert the facial landmark (x, y)-coordinates to a NumPy\u001b[39;00m\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;66;03m# array\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'detector' is not defined"
     ]
    }
   ],
   "source": [
    "# First, start the videostream again:\n",
    "vs = VideoStream(src=camSrc).start()\n",
    "time.sleep(1.0)\n",
    "\n",
    "ii=0 # Keep track of how many times we've looped\n",
    "while True:\n",
    "    # grab the frame from the threaded video file stream, resize\n",
    "    # it, and convert it to grayscale\n",
    "    # channels)\n",
    "\n",
    "    frame = vs.read()\n",
    "    frame = imutils.resize(frame, width=450)\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #\n",
    "    # detect faces in the grayscale frame\n",
    "    rects = detector(gray, 0)\n",
    "    \n",
    "    # loop over the face detections\n",
    "    for rect in rects:\n",
    "        # determine the facial landmarks for the face region, then\n",
    "        # convert the facial landmark (x, y)-coordinates to a NumPy\n",
    "        # array\n",
    "        shape = predictor(gray, rect)\n",
    "        shape = face_utils.shape_to_np(shape)\n",
    " \n",
    "        \n",
    "        ##############\n",
    "        # get centered version scaled wrt face width and height\n",
    "        scaledShape = scaleFace(shape)\n",
    "        chinPt = shape[8] # We'll use this to place text\n",
    "        faceWidth = shape[16,0] - shape[0,0] # And this too\n",
    "        \n",
    "        # Gather covariates\n",
    "        faceInput = facedat(scaledShape)\n",
    "        \n",
    "        # Figure out to whom the face belongs\n",
    "        ident = int(clf.predict(np.array(faceInput).reshape(1,-1)))\n",
    "        txtcol = [(0,0,255),(0,255,0)][ident]\n",
    "        ident = personNames[ident]\n",
    "        \n",
    "        # Annotate the image with the identity\n",
    "        cv2.putText(frame, ident[0], \n",
    "            (int(chinPt[0]-faceWidth/4),chinPt[1]+20),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX, 0.7, txtcol, 2)\n",
    "        ##################\n",
    "        \n",
    "        \n",
    "    # show the frame\n",
    "    cv2.imshow(\"Frame\", frame)\n",
    "    #cv2.imwrite('images\\\\'+str(ii).zfill(5)+'.png',frame) # Uncomment this to save each frame as .png\n",
    "    ii+=1 # Increment loop count\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    " \n",
    "    # if the `q` key was pressed, break from the loop\n",
    "    if key == ord(\"q\"):\n",
    "        break\n",
    "        \n",
    "# do a bit of cleanup\n",
    "cv2.destroyAllWindows()\n",
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ade6992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aedb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
